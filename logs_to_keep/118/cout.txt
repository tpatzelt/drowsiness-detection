Starting experiment on 60 sec data with 2 targets.
loading data
X_train shape: (26642, 1800, 7), y_train shape: (26642,)
X_test shape: (6494, 1800, 7), y_test shape: (6494,)
starting hyperparameter search
Fitting 1 folds for each of 10 candidates, totalling 10 fits
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d (Conv1D)              (None, 600, 124)          4464      
_________________________________________________________________
batch_normalization (BatchNo (None, 600, 124)          496       
_________________________________________________________________
re_lu (ReLU)                 (None, 600, 124)          0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 200, 124)          77004     
_________________________________________________________________
batch_normalization_1 (Batch (None, 200, 124)          496       
_________________________________________________________________
re_lu_1 (ReLU)               (None, 200, 124)          0         
_________________________________________________________________
global_average_pooling1d (Gl (None, 124)               0         
_________________________________________________________________
dense (Dense)                (None, 32)                4000      
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 33        
=================================================================
Total params: 86,493
Trainable params: 85,997
Non-trainable params: 496
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 1800, 86)          3096      
_________________________________________________________________
batch_normalization_2 (Batch (None, 1800, 86)          344       
_________________________________________________________________
re_lu_2 (ReLU)               (None, 1800, 86)          0         
_________________________________________________________________
global_average_pooling1d_1 ( (None, 86)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2784      
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 6,257
Trainable params: 6,085
Non-trainable params: 172
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 360, 108)          2376      
_________________________________________________________________
batch_normalization_3 (Batch (None, 360, 108)          432       
_________________________________________________________________
re_lu_3 (ReLU)               (None, 360, 108)          0         
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 72, 108)           35100     
_________________________________________________________________
batch_normalization_4 (Batch (None, 72, 108)           432       
_________________________________________________________________
re_lu_4 (ReLU)               (None, 72, 108)           0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 15, 108)           35100     
_________________________________________________________________
batch_normalization_5 (Batch (None, 15, 108)           432       
_________________________________________________________________
re_lu_5 (ReLU)               (None, 15, 108)           0         
_________________________________________________________________
global_average_pooling1d_2 ( (None, 108)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 32)                3488      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 33        
=================================================================
Total params: 77,393
Trainable params: 76,745
Non-trainable params: 648
_________________________________________________________________
None
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 600, 73)           1606      
_________________________________________________________________
batch_normalization_6 (Batch (None, 600, 73)           292       
_________________________________________________________________
re_lu_6 (ReLU)               (None, 600, 73)           0         
_________________________________________________________________
global_max_pooling1d (Global (None, 73)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 32)                2368      
_________________________________________________________________
dropout_3 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 33        
=================================================================
Total params: 4,299
Trainable params: 4,153
Non-trainable params: 146
_________________________________________________________________
None
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 600, 108)          2376      
_________________________________________________________________
batch_normalization_7 (Batch (None, 600, 108)          432       
_________________________________________________________________
re_lu_7 (ReLU)               (None, 600, 108)          0         
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 200, 108)          35100     
_________________________________________________________________
batch_normalization_8 (Batch (None, 200, 108)          432       
_________________________________________________________________
re_lu_8 (ReLU)               (None, 200, 108)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 108)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 32)                3488      
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 33        
=================================================================
Total params: 41,861
Trainable params: 41,429
Non-trainable params: 432
_________________________________________________________________
None
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_9 (Conv1D)            (None, 360, 61)           1342      
_________________________________________________________________
batch_normalization_9 (Batch (None, 360, 61)           244       
_________________________________________________________________
re_lu_9 (ReLU)               (None, 360, 61)           0         
_________________________________________________________________
conv1d_10 (Conv1D)           (None, 72, 61)            11224     
_________________________________________________________________
batch_normalization_10 (Batc (None, 72, 61)            244       
_________________________________________________________________
re_lu_10 (ReLU)              (None, 72, 61)            0         
_________________________________________________________________
conv1d_11 (Conv1D)           (None, 15, 61)            11224     
_________________________________________________________________
batch_normalization_11 (Batc (None, 15, 61)            244       
_________________________________________________________________
re_lu_11 (ReLU)              (None, 15, 61)            0         
_________________________________________________________________
global_max_pooling1d_2 (Glob (None, 61)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 32)                1984      
_________________________________________________________________
dropout_5 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 33        
=================================================================
Total params: 26,539
Trainable params: 26,173
Non-trainable params: 366
_________________________________________________________________
None
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_12 (Conv1D)           (None, 360, 44)           1584      
_________________________________________________________________
batch_normalization_12 (Batc (None, 360, 44)           176       
_________________________________________________________________
re_lu_12 (ReLU)              (None, 360, 44)           0         
_________________________________________________________________
conv1d_13 (Conv1D)           (None, 72, 44)            9724      
_________________________________________________________________
batch_normalization_13 (Batc (None, 72, 44)            176       
_________________________________________________________________
re_lu_13 (ReLU)              (None, 72, 44)            0         
_________________________________________________________________
global_max_pooling1d_3 (Glob (None, 44)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 32)                1440      
_________________________________________________________________
dropout_6 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 33        
=================================================================
Total params: 13,133
Trainable params: 12,957
Non-trainable params: 176
_________________________________________________________________
None
Model: "model_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_14 (Conv1D)           (None, 1800, 18)          648       
_________________________________________________________________
batch_normalization_14 (Batc (None, 1800, 18)          72        
_________________________________________________________________
re_lu_14 (ReLU)              (None, 1800, 18)          0         
_________________________________________________________________
global_average_pooling1d_3 ( (None, 18)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 32)                608       
_________________________________________________________________
dropout_7 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 33        
=================================================================
Total params: 1,361
Trainable params: 1,325
Non-trainable params: 36
_________________________________________________________________
None
Model: "model_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_15 (Conv1D)           (None, 1800, 23)          506       
_________________________________________________________________
batch_normalization_15 (Batc (None, 1800, 23)          92        
_________________________________________________________________
re_lu_15 (ReLU)              (None, 1800, 23)          0         
_________________________________________________________________
conv1d_16 (Conv1D)           (None, 1800, 23)          1610      
_________________________________________________________________
batch_normalization_16 (Batc (None, 1800, 23)          92        
_________________________________________________________________
re_lu_16 (ReLU)              (None, 1800, 23)          0         
_________________________________________________________________
conv1d_17 (Conv1D)           (None, 1800, 23)          1610      
_________________________________________________________________
batch_normalization_17 (Batc (None, 1800, 23)          92        
_________________________________________________________________
re_lu_17 (ReLU)              (None, 1800, 23)          0         
_________________________________________________________________
global_max_pooling1d_4 (Glob (None, 23)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 32)                768       
_________________________________________________________________
dropout_8 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 33        
=================================================================
Total params: 4,803
Trainable params: 4,665
Non-trainable params: 138
_________________________________________________________________
None
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_18 (Conv1D)           (None, 600, 39)           1404      
_________________________________________________________________
batch_normalization_18 (Batc (None, 600, 39)           156       
_________________________________________________________________
re_lu_18 (ReLU)              (None, 600, 39)           0         
_________________________________________________________________
conv1d_19 (Conv1D)           (None, 200, 39)           7644      
_________________________________________________________________
batch_normalization_19 (Batc (None, 200, 39)           156       
_________________________________________________________________
re_lu_19 (ReLU)              (None, 200, 39)           0         
_________________________________________________________________
global_max_pooling1d_5 (Glob (None, 39)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 32)                1280      
_________________________________________________________________
dropout_9 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 33        
=================================================================
Total params: 10,673
Trainable params: 10,517
Non-trainable params: 156
_________________________________________________________________
None
finished finding the best hyperparameters
start training best model on complete training and validation data
Model: "model_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 1800, 7)]         0         
_________________________________________________________________
conv1d_20 (Conv1D)           (None, 360, 44)           1584      
_________________________________________________________________
batch_normalization_20 (Batc (None, 360, 44)           176       
_________________________________________________________________
re_lu_20 (ReLU)              (None, 360, 44)           0         
_________________________________________________________________
conv1d_21 (Conv1D)           (None, 72, 44)            9724      
_________________________________________________________________
batch_normalization_21 (Batc (None, 72, 44)            176       
_________________________________________________________________
re_lu_21 (ReLU)              (None, 72, 44)            0         
_________________________________________________________________
global_max_pooling1d_6 (Glob (None, 44)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 32)                1440      
_________________________________________________________________
dropout_10 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 33        
=================================================================
Total params: 13,133
Trainable params: 12,957
Non-trainable params: 176
_________________________________________________________________
None
log scores and training and test set
  1/833 [..............................] - ETA: 1:25 - loss: 0.8068 - accuracy: 0.5312 23/833 [..............................] - ETA: 1s - loss: 0.6741 - accuracy: 0.6984   45/833 [>.............................] - ETA: 1s - loss: 0.4560 - accuracy: 0.7951 66/833 [=>............................] - ETA: 1s - loss: 0.5085 - accuracy: 0.7699 87/833 [==>...........................] - ETA: 1s - loss: 0.5264 - accuracy: 0.7730109/833 [==>...........................] - ETA: 1s - loss: 0.5481 - accuracy: 0.7517131/833 [===>..........................] - ETA: 1s - loss: 0.5251 - accuracy: 0.7564153/833 [====>.........................] - ETA: 1s - loss: 0.5294 - accuracy: 0.7549175/833 [=====>........................] - ETA: 1s - loss: 0.5668 - accuracy: 0.7254197/833 [======>.......................] - ETA: 1s - loss: 0.5257 - accuracy: 0.7440218/833 [======>.......................] - ETA: 1s - loss: 0.5071 - accuracy: 0.7547240/833 [=======>......................] - ETA: 1s - loss: 0.4842 - accuracy: 0.7656262/833 [========>.....................] - ETA: 1s - loss: 0.4791 - accuracy: 0.7711284/833 [=========>....................] - ETA: 1s - loss: 0.4687 - accuracy: 0.7740305/833 [=========>....................] - ETA: 1s - loss: 0.4643 - accuracy: 0.7767327/833 [==========>...................] - ETA: 1s - loss: 0.4420 - accuracy: 0.7875348/833 [===========>..................] - ETA: 1s - loss: 0.4344 - accuracy: 0.7951370/833 [============>.................] - ETA: 1s - loss: 0.4261 - accuracy: 0.8008391/833 [=============>................] - ETA: 1s - loss: 0.4198 - accuracy: 0.7978412/833 [=============>................] - ETA: 0s - loss: 0.4273 - accuracy: 0.7947434/833 [==============>...............] - ETA: 0s - loss: 0.4358 - accuracy: 0.7917456/833 [===============>..............] - ETA: 0s - loss: 0.4244 - accuracy: 0.7983478/833 [================>.............] - ETA: 0s - loss: 0.4496 - accuracy: 0.7776500/833 [=================>............] - ETA: 0s - loss: 0.4420 - accuracy: 0.7827521/833 [=================>............] - ETA: 0s - loss: 0.4321 - accuracy: 0.7877542/833 [==================>...........] - ETA: 0s - loss: 0.4247 - accuracy: 0.7920564/833 [===================>..........] - ETA: 0s - loss: 0.4226 - accuracy: 0.7923585/833 [====================>.........] - ETA: 0s - loss: 0.4228 - accuracy: 0.7930607/833 [====================>.........] - ETA: 0s - loss: 0.4247 - accuracy: 0.7938628/833 [=====================>........] - ETA: 0s - loss: 0.4220 - accuracy: 0.7966649/833 [======================>.......] - ETA: 0s - loss: 0.4087 - accuracy: 0.8032670/833 [=======================>......] - ETA: 0s - loss: 0.4020 - accuracy: 0.8081691/833 [=======================>......] - ETA: 0s - loss: 0.3997 - accuracy: 0.8073712/833 [========================>.....] - ETA: 0s - loss: 0.4066 - accuracy: 0.8019734/833 [=========================>....] - ETA: 0s - loss: 0.4073 - accuracy: 0.8026755/833 [==========================>...] - ETA: 0s - loss: 0.4153 - accuracy: 0.7990777/833 [==========================>...] - ETA: 0s - loss: 0.4246 - accuracy: 0.7965799/833 [===========================>..] - ETA: 0s - loss: 0.4219 - accuracy: 0.7966820/833 [============================>.] - ETA: 0s - loss: 0.4233 - accuracy: 0.7959833/833 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.7974
  1/203 [..............................] - ETA: 2s - loss: 0.8068 - accuracy: 0.5312 23/203 [==>...........................] - ETA: 0s - loss: 0.6741 - accuracy: 0.6984 44/203 [=====>........................] - ETA: 0s - loss: 0.8081 - accuracy: 0.6712 66/203 [========>.....................] - ETA: 0s - loss: 0.8362 - accuracy: 0.5843 88/203 [============>.................] - ETA: 0s - loss: 1.1869 - accuracy: 0.5032110/203 [===============>..............] - ETA: 0s - loss: 1.0074 - accuracy: 0.5679131/203 [==================>...........] - ETA: 0s - loss: 0.9158 - accuracy: 0.6011152/203 [=====================>........] - ETA: 0s - loss: 1.0975 - accuracy: 0.5800173/203 [========================>.....] - ETA: 0s - loss: 1.1229 - accuracy: 0.5816195/203 [===========================>..] - ETA: 0s - loss: 1.2005 - accuracy: 0.5771203/203 [==============================] - 0s 2ms/step - loss: 1.1921 - accuracy: 0.5768
