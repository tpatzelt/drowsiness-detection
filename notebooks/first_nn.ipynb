{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from drowsiness_detection import config\n",
    "from drowsiness_detection.models import build_dummy_tf_classifier, ThreeDStandardScaler,build_dense_model, build_lstm_model, build_cnn_model\n",
    "import tensorflow.keras as keras\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('/home/tim/Windows/Windows_30_Hz/WindowData/10_sec')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 10\n",
    "recording_frequency = 30\n",
    "exclude_by = \"a\"\n",
    "\n",
    "config.set_paths(recording_frequency, window_size)\n",
    "config.PATHS.WINDOW_DATA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300, 7) (20,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "X = np.random.random(num_samples * 300 * 7).reshape((num_samples, 300, 7))\n",
    "y = np.concatenate((np.zeros((num_samples // 2)), np.ones((num_samples // 2))))\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300, 7)\n"
     ]
    }
   ],
   "source": [
    "scaler = ThreeDStandardScaler()\n",
    "X_scaled = scaler.fit_transform(X, y)\n",
    "print(X_scaled.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Input = namedtuple(\"Input\", \"X y\")\n",
    "input = Input(X_scaled, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.01\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 10.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "\n",
    "\n",
    "def test_model(model, input: Input = input):\n",
    "    batch_size = 2\n",
    "    epochs = 2\n",
    "    X = tf.convert_to_tensor(input.X, dtype=tf.float64)\n",
    "    y = tf.convert_to_tensor(input.y, dtype=tf.int8)\n",
    "\n",
    "    lrate = keras.callbacks.LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [lrate]\n",
    "\n",
    "    model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
    "    score = model.evaluate(X_scaled, y)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation was set to None which is not supported.\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 6.4064 - accuracy: 0.3333 - val_loss: 0.3278 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.4064 - accuracy: 0.3333 - val_loss: 0.3278 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.7986 - accuracy: 0.4000\n",
      "Test loss: 5.798554420471191\n",
      "Test accuracy: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_dummy_tf_classifier(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 2100)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                134464    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,529\n",
      "Trainable params: 134,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9065 - accuracy: 0.4444 - val_loss: 0.4561 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.4444 - val_loss: 0.4413 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0449 - accuracy: 0.5000\n",
      "Test loss: 0.04489997401833534\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_dense_model(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape,\n",
    "                    kernel_size=(5, 1),\n",
    "                    stride=(3, 1),\n",
    "                    num_filters=32,\n",
    "                    padding=\"valid\",\n",
    "                    use_batch_norm=True,\n",
    "                    lr=.001):\n",
    "    input_layer = keras.layers.Input(input_shape[1:])\n",
    "    try:\n",
    "        reshape_layer = keras.layers.Reshape(input_shape[1:] + [1,])(input_layer)\n",
    "    except TypeError:\n",
    "        reshape_layer = keras.layers.Reshape(input_shape[1:] + (1,))(input_layer)\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, strides=stride,\n",
    "                                padding=padding)(reshape_layer)\n",
    "    if use_batch_norm:\n",
    "        conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, padding=padding)(\n",
    "        conv1)\n",
    "    if use_batch_norm:\n",
    "        conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, padding=padding)(\n",
    "        conv2)\n",
    "    if use_batch_norm:\n",
    "        conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling2D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(gap)\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    # Compile model\n",
    "    # callbacks = [\n",
    "    # keras.callbacks.ReduceLROnPlateau(\n",
    "    #     monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    # ),\n",
    "    # keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "    # ]\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def build_cnn_model_1d(input_shape,\n",
    "                    kernel_size=5,\n",
    "                    stride=1,\n",
    "                    num_filters=32,\n",
    "                    num_conv_layers=2,\n",
    "                    padding=\"same\",\n",
    "                    use_batch_norm=True,\n",
    "                    lr=0.1,\n",
    "                    pooling=\"average\"):\n",
    "    input_layer = keras.layers.Input(input_shape[1:])\n",
    "    prev_layer = input_layer\n",
    "    for _ in range(num_conv_layers):\n",
    "        conv_layer = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride,\n",
    "                                    padding=padding)(prev_layer)\n",
    "        if use_batch_norm:\n",
    "            conv_layer = keras.layers.BatchNormalization()(conv_layer)\n",
    "        conv_layer = keras.layers.ReLU()(conv_layer)\n",
    "        prev_layer = conv_layer\n",
    "\n",
    "    if pooling == \"average\":\n",
    "        pool_layer = keras.layers.GlobalAveragePooling1D()(prev_layer)\n",
    "    elif pooling == \"max\":\n",
    "        pool_layer = keras.layers.GlobalMaxPool1D()(prev_layer)\n",
    "    else:\n",
    "        pool_layer = prev_layer\n",
    "\n",
    "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(pool_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 300, 7)]          0         \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 300, 32)           1152      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 300, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_28 (ReLU)             (None, 300, 32)           0         \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 300, 32)           5152      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 300, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_29 (ReLU)             (None, 300, 32)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,593\n",
      "Trainable params: 6,465\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 1s 19ms/step - loss: 9.0908 - accuracy: 0.4444 - val_loss: 76.3805 - val_accuracy: 0.0000e+00 - lr: 0.1000\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.9395 - accuracy: 0.4444 - val_loss: 1.2145e-08 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 9.7648 - accuracy: 0.5000\n",
      "Test loss: 9.764841079711914\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_cnn_model_1d(input_shape=X.shape, pooling=\"max\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9/9 [==============================] - 4s 251ms/step - loss: 0.7312 - accuracy: 0.3889 - val_loss: 0.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 2s 168ms/step - loss: 0.2767 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.2074 - accuracy: 0.9000\n",
      "Test loss: 0.20741109549999237\n",
      "Test accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_lstm_model(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "use real data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}