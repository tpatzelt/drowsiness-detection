{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from drowsiness_detection import config\n",
    "from drowsiness_detection.models import build_dummy_tf_classifier, ThreeDStandardScaler, build_dense_model, build_lstm_model, build_cnn_model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('/media/tim/My Passport/drowsiness_data/Windows/Windows_30_Hz/WindowData/10_sec')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 10\n",
    "recording_frequency = 30\n",
    "exclude_by = \"a\"\n",
    "\n",
    "config.set_paths(recording_frequency, window_size)\n",
    "config.PATHS.WINDOW_DATA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300, 23) (20,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "X = np.random.random(num_samples * 300 * 23).reshape((num_samples, 300, 23))\n",
    "y = np.concatenate((np.zeros((num_samples // 2)), np.ones((num_samples // 2))))\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300, 23)\n"
     ]
    }
   ],
   "source": [
    "scaler = ThreeDStandardScaler()\n",
    "X_scaled = scaler.fit_transform(X, y)\n",
    "print(X_scaled.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Input = namedtuple(\"Input\", \"X y\")\n",
    "input = Input(X_scaled, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def test_model(model, input: Input = input):\n",
    "    batch_size = 2\n",
    "    epochs = 2\n",
    "    X = tf.convert_to_tensor(input.X, dtype=tf.float64)\n",
    "    y = tf.convert_to_tensor(input.y, dtype=tf.int8)\n",
    "    model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    score = model.evaluate(X_scaled, y)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9/9 [==============================] - 1s 18ms/step - loss: 0.8379 - accuracy: 0.5000 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 2.6963e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Test loss: 0.02810894325375557\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_dense_model(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation was set to None which is not supported.\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.8302 - accuracy: 0.3333 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.2554 - accuracy: 0.7222 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.3724 - accuracy: 0.6500\n",
      "Test loss: 5.37237548828125\n",
      "Test accuracy: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_dummy_tf_classifier(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 300, 23)]         0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 300, 23, 1)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 99, 23, 32)        192       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 99, 23, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 99, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 95, 23, 32)        5152      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 95, 23, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 95, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 91, 23, 32)        5152      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 91, 23, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 91, 23, 32)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,913\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.6761 - accuracy: 0.6250WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7f69001f9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "9/9 [==============================] - 1s 39ms/step - loss: 0.6926 - accuracy: 0.5556 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6841 - accuracy: 0.5556 - val_loss: 0.6850 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f69001f9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Test loss: 0.692489504814148\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_cnn_model(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9/9 [==============================] - 4s 208ms/step - loss: 0.7000 - accuracy: 0.4444 - val_loss: 0.6142 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Test loss: 0.11697981506586075\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_model(model=build_lstm_model(input_shape=X.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}