{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from drowsiness_detection.data import (session_type_mapping, load_experiment_objects,\n",
    "                                       load_preprocessed_train_test_splits,\n",
    "                                       train_test_split_by_subjects,\n",
    "                                       get_feature_data, preprocess_feature_data, load_preprocessed_train_val_test_splits)\n",
    "from drowsiness_detection import config\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 14, 7\n",
    "\n",
    "MIN_LABELS, MAX_LABELS = 0, 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_id = 49\n",
    "exp_config, best_estimator, _ = load_experiment_objects(experiment_id=experiment_id)\n",
    "\n",
    "window_size = exp_config[\"window_in_sec\"]\n",
    "config.set_paths(30, window_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create training, validation and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = load_preprocessed_train_val_test_splits(\n",
    "    data_path=config.PATHS.WINDOW_FEATURES,\n",
    "    exclude_sess_type=session_type_mapping[exp_config[\"exclude_by\"]],\n",
    "    num_targets=exp_config[\"num_targets\"],\n",
    "    seed=exp_config[\"seed\"],\n",
    "    test_size=exp_config[\"test_size\"],\n",
    "    split_by_subjects=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of samples in training, validation and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.array([0, 1])\n",
    "width = .25\n",
    "bins = [0, .5, 1]\n",
    "\n",
    "rects1 = ax.bar(x, np.histogram(y_train, bins=bins)[0], width, label=\"train labels\")\n",
    "rects2 = ax.bar(x + width, np.histogram(y_test, bins=bins)[0], width, label=\"test labels\")\n",
    "rects3 = ax.bar(x + width * 2, np.histogram(y_val, bins=bins)[0], width, label=\"val labels\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Number of labels\")\n",
    "ax.set_title(\"Distribution of labels (not drowsy=0, drowsy=1)\")\n",
    "ax.set_xticks(x + width, x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "see how subject ids are distributed within splits with different seeds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_test_ids, all_train_ids = [], []\n",
    "for _ in range(10):\n",
    "    data = get_feature_data(data_path=config.PATHS.WINDOW_FEATURES)\n",
    "    X, y, subject_data = preprocess_feature_data(feature_data=data,\n",
    "                                   exclude_sess_type=session_type_mapping[exp_config[\"exclude_by\"]],\n",
    "                                   num_targets=exp_config[\"num_targets\"])\n",
    "    X_train, X_test, y_train, y_test, (train_ids, test_ids), _ = train_test_split_by_subjects(X, y,\n",
    "                                                                                           num_targets=\n",
    "                                                                                           exp_config[\n",
    "                                                                                               \"num_targets\"],\n",
    "                                                                                           test_size=\n",
    "                                                                                           exp_config[\n",
    "                                                                                               \"test_size\"], subject_data=subject_data)\n",
    "    all_train_ids.append(train_ids)\n",
    "    all_test_ids.append(test_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_data_splits(all_ids):\n",
    "    same_counts = []\n",
    "    for train_ids1 in all_ids:\n",
    "        for train_ids2 in all_ids:\n",
    "            if np.array_equal(train_ids1, train_ids2):\n",
    "                continue\n",
    "            same_count = 0\n",
    "            for train_id in train_ids1:\n",
    "                if train_id in train_ids2:\n",
    "                    same_count += 1\n",
    "            same_counts.append(same_count / len(train_ids1))\n",
    "    return same_counts\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"on average there were {np.mean(compare_data_splits(all_train_ids))} of ids in the other training sets\")\n",
    "print(\n",
    "    f\"on average there were {np.mean(compare_data_splits(all_test_ids))} of ids in the other test sets\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment with splitting of dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(criterion=\"entropy\",\n",
    "                                    max_depth=80,\n",
    "                                    max_features=\"sqrt\",\n",
    "                                    n_estimators=512,\n",
    "                                    class_weight=\"balanced\",\n",
    "                                    n_jobs=-2,\n",
    "                                    min_samples_split=0.01\n",
    "                                    )\n",
    "scaler = StandardScaler()\n",
    "pipe = make_pipeline(scaler, classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"train score: {pipe.score(X_train, y_train)}\")\n",
    "print(f\"test score: {pipe.score(X_test, y_test)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing different hyperparameters to improve train score with seed 2:\n",
    "max samples: 0.6\n",
    "train score: 0.7468598103854853\n",
    "test score: 1.0\n",
    "\n",
    "max samples: 0.2\n",
    "train score: 0.7334327927234227\n",
    "test score: 0.9955974288984767\n",
    "\n",
    "-> max samples not so effective to improve generalization\n",
    "\n",
    "min samples split reduces train score -> better generalization?\n",
    "test the above on different window sizes:\n",
    "10 sec:\n",
    "train score: 0.88226737779345\n",
    "test score: 0.8298574764473791\n",
    "\n",
    "20 sec:\n",
    "train score: 0.8819999117426416\n",
    "test score: 0.8738503079908868\n",
    "\n",
    "60 sec:\n",
    "train score: 0.9486186298301288\n",
    "test score: 0.7993089279043706"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing different seed for splitting data by subjects:\n",
    "\n",
    "seed 123:\n",
    "[(20782, 787), (20782,), (11354, 787), (11354,)]\n",
    "train score: 0.7130690020209797\n",
    "test score: 1.0\n",
    "\n",
    "seed 42:\n",
    "[(21421, 787), (21421,), (10715, 787), (10715,)]\n",
    "train score: 0.7201811306661687\n",
    "test score: 1.0\n",
    "\n",
    "seed 1:\n",
    "[(21105, 787), (21105,), (11031, 787), (11031,)]\n",
    "train score: 0.7194029850746269\n",
    "test score: 1.0\n",
    "\n",
    "seed 2:\n",
    "[(20779, 787), (20779,), (11357, 787), (11357,)]\n",
    "train score: 0.7597093219115453\n",
    "test score: 1.0\n",
    "\n",
    "--> yields very similar results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
